---
title: 'Homework 3: The Death and Life of Great American City Scaling Laws'
author: "DingHuan, 3170102085"
output: pdf_document
---
```{r,echo = F, message = F}
library(tidyverse)
```

1. 
    ```{r, message = F}
    gmp <- read.table("gmp.dat")
    gmp$pop <- round(gmp$gmp/gmp$pcgmp)
    gmp <- gmp %>% mutate(nlmfit = 6611*pop^(1/8),
                          a0.1 = 6611*pop^(0.1),
                          a0.15 = 6611*pop^(0.15))
    gmp %>% ggplot + geom_point(aes(x = pop, y = pcgmp)) +
      labs(x = "Population", y = "Per-Capita Economic Output ($/person-year)",
          title = "US Metropolitan Areas, 2006") + 
      geom_line(aes(x = pop, y = nlmfit), col = '#00BFC4') + 
      geom_line(aes(x = pop, y = a0.1), col = '#F8766D') +
      geom_line(aes(x = pop, y = a0.15), col = '#7CAE00') +
      scale_x_log10()
```

2. 
    ```{r}
    mse <- function(vari, N = gmp$pop, Y = gmp$pcgmp){
      m = mean((Y - vari[1] * N ^ vari[2])^2)
      return(m)
    }
    mse(c(6611,0.15))
    mse(c(5000,0.10))
    ```

4. The quantity `minimum` represents the optimizing result, the minimum of `mse()` by `nlm()` with Newton-type optimizing algorithm. The quantity `estimate` represents the end of optimizing iteration, the optimal point estimated by `nlm()`. On the other words, `mse()` have a minimum value `minimum`, which is obtained at point `estimate`.
    ```{r, warning=FALSE}
    nlm(mse, c(y0=6611,a=1/8))
    nlm(mse, c(y0=6600,a=0.1))
    nlm(mse, c(y0=6000,a=0.1))
    ```

5. The estimates for those two pairs of parameters are different. Because the robustness of the algorithm is not good enough, and there are plenty of local optimal points around the global one, so the results fall on the local ones with an unexpected starting points.
    ```{r, warning=F}
    plm <- function(y0, a, N = gmp$pop, Y = gmp$pcgmp){
      pari = c(y0, a)
      mse_tem <- function(vari) mse(vari,N,Y)
      n <- nlm(mse_tem, pari)
      m = list(final_guess_y0 = n$estimate[1], 
               final_guess_a = n$estimate[2], 
               final_value_MSE = n$minimum)
      return(m)
    }
    plm(6611,0.15)
    plm(5000,0.10)
    ```

6. 
    a. 
    ```{r}
    mean(gmp$pcgmp)
    sd(gmp$pcgmp) / sqrt(length(gmp$pcgmp))
    ```
    b. 
    ```{r}
    except <- function(i){
      m = mean(gmp[-i,"pcgmp"])
      return(m)
    }
    ```
    c. 
    ```{r}
    jackknifed.means <- sapply(1:nrow(gmp), except)
    ```
    d. It matches quite well.
    ```{r}
    n <- length(jackknifed.means)
    m <- mean(jackknifed.means)
    sqrt(sum((jackknifed.means-m)^2)*(n-1)/n)
    ```
    
7. 
    ```{r,warning = F}
    plm.jackknife <- function(y0, a, data = gmp){
      jackknifed.gmp <- data.frame()
      for (i in 1:nrow(data)){
        m = data.frame(plm(y0, a, N = data[-i,"pop"], Y=data[-i,"pcgmp"]))
        jackknifed.gmp <- rbind(jackknifed.gmp, m)
      }
      y0 <- jackknifed.gmp$final_guess_y0
      a <- jackknifed.gmp$final_guess_a
      n <- nrow(jackknifed.gmp)
      y0 <- sqrt(sum((y0 - mean(y0))^2)*(n-1)/n)
      a <- sqrt(sum((a - mean(a))^2)*(n-1)/n)
      v <- c(y0, a)
      return(v)
    }
    plm.jackknife(6600,0.1)
    ```
    
8. The parameters didn't change a lot.
    ```{r,warning = F}
    gmp.2013 = read.table("gmp-2013.dat")
    gmp.2013$pop <- round(gmp.2013$gmp / gmp.2013$pcgmp)
    plm(6600,0.1,gmp.2013$pop,gmp.2013$pcgmp)
    plm.jackknife(6600,0.1,gmp.2013)
    ```
    